## A practical research project on optimizing neural networks for the purpose of text classification.

Neural networks have been increasingly used for various complex tasks such as image recognition, text generation, translation, etc. Their ability to learn patterns from data with or without supervision has been a key factor in their success. However, their tuning and optimization remains an active area of research. This research project aims to study the optimization process of the neural nets. The chosen task for this optimization is text classification. Text classification is an important task which has numerous uses like spam detection, article organization, sentiment analysis, etc. So, this research focused on optimizing the neural nets for text classification. In this research, 2 datasets were selected for text classification â€“ a reviews dataset and a news articles dataset. Then 3 neural net architectures (FNN, CNN, and RNN) were explored and evaluated. For each of the architecture, a total of 9 different hyperparameters were also tested with different values, in a sequential order. At each step, the best performing configuration of neural nets was shortlisted. In the end, two best models of neural nets were found, one for each dataset. A 3-layered CNN model was found to be most optimized model for the reviews dataset and a 1-layered FNN model was the most optimized model for the news dataset. It was also found that several hyperparameters affect the accuracy and loss of the neural networks in different ways. At the end, through this research, it was established that the choice of architecture and tuning of the hyperparameters significantly improve the performance of the neural networks for text classification.
