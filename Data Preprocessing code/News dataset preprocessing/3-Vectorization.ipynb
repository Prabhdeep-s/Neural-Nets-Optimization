{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "from fasttext import load_model\n",
    "import gensim\n",
    "import tensorflow as tf\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import collections\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"..\\Dataset3\\IAB_News_tokenized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new delhi indian men hockey team medal less rudder less commonwealth game performance bring chief coach sjoerd marijne scanner hockey india schedule performance review meeting later week also read cwg indian men hockey team lose england bronze play offit learn senior player team lead skipper manpreet singh pr sreejesh rupinder pal singh meet top hi official tuesday present explanation performance first time year since india fail win single medal hockey cwg go well national federation say win shy away take tough decision review meeting accord hockey india official player coach performance also scrutinise corrective measure take need three important tournament champion trophy asian game season end world cup line year performance gold coast definitely acceptable par say least provide facility team fail deliver big event hi official say one medal favourites look perform low ranked team like wale pakistan new zealand england india particularly poor draw pakistan concede equaliser seven second leave clock earlier report senior player unhappy chief coach marijne decision blood youngster like vivek sagar prasad dilpreet singh sumit gurinder singh place experienced pro sardar singh ramandeep singh cwg bound squad hi official say issue examine review meeting hockey team game coach also accountable player performance early comment anything sjoerd come answer poor show past hi hire fire policy foreign coach include marijne predecessor roelant oltmans terry walsh michael nobbs ric charlesworth come sharp criticism even though marijne draw salary sport authority india hi review performance marijne presently home netherlands expect join national camp bengaluru april source say would arrive india first week may due visa issue\n",
      "level cut short eat plenty fruit vegetable appropriate cholesterol rich food drink plenty water sometimes limited amount alcohol keep happy stress free smoke fresh air brisk walk daily exercise brain negative thought stress muscle keep active healthy enjoy life way come think happens best best luck article contribute dr amit sinkar mbbs dnb med dnb card consultant cardiologist mmf joshi ratna hospital punee mail dramitsinkar yahoo comdisclaimer view opinion express doctor independent professional judgment take responsibility accuracy view consider substitute physician advice please consult treat physician detail\n",
      "grocery store apartment complex long day work still whip meal family order often healthy option turn neighbour many big apartment complex resident passion cook try different dish loved one home anyone one else vicinity nominal price apartment complex jp nagar nanda jain live app especially resident put information cook house want sample dish call take back home cook food every day nanda updates people complex lunch dinner snack menu make vada pav tea time make extra one order eat home way none resource get waste get cash well work party get finish whatever food make person get feast home cook dish say nanda nidhi mehta mother two begin try different dish home kid always seek something new eat digest spicy oily food restaurant become hobby soon business resident begur supply lunch dinner people apartment complex five kilometre radius want people taste north indian cuisine start cater birthday party friend motivate take everyday basis provide vegetarian non vegetarian lunch dinner every day special dish weekend plan menu two day advance make much require order receive say manage also take care two school go child get order lunch ready pm dinner order come around pm spend time child say nidhi nanda nidhi clientele include bachelor family advertising say word mouth\n",
      "mirror writer single mom anjana vaswani chat three others tribe raise kid alone one eye blood pressure two month ago day final round admission kindergarten grade right education quota panic single mother flock bmc help centre application reject father income certificate miss mother certificate acceptable substitute make newspaper copy ask single mother tell niggle like regular part life official paperwork nightmare patriarchal system garnish gateau stress guilt feeling isolation stigma self doubt health likely impact negatively long run answer though obvious confirm study publish journal epidemiology community health assess woman across country focus woman child age also examine whether alone worse country relatively weak social safety net vital point social structure may redeemer alleviate guilt leave child grandparent allow us time fitness routine together may render study altogether inapposite mean get write us yet see friend many lot young negotiate around rise garden marriage ache back knee thyroid problem frequently also treat headache family politics feel confident least good shot health longevity suddenly health become top priority anita khiara stay home mum daughter separate nine six since live abroad move mumbai postdivorce make challenging grapple whole different culture one even realise health head downward time appear like bout illness first three month lose enough weight drop unhealthy size zero end fracture arm realise health cry attention consistent ache pain realise arose partly due stress accompany move home course separate someone year case count courtship matter anyone say scary year wonder able provide us child right see father cry remember hard hurt divorce cause return city\n",
      "work entire body help achieve hand eye coordination gradually master basic activity challenge far use different pattern like side step speed step cross mode moderate level lose much calorie perform activity hour jogging jogging another ideal way work every part body shed unwanted calorie order achieve best calorie burn potential attempt work mph also offer resistance motion use rugged rough terrain hilly inclined area read personal health diet fitness story www healthmeup com\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "for txt in data[0:5]['Text']:\n",
    "    print(txt.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='int64')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.isnull().any(axis=1)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483567\n"
     ]
    }
   ],
   "source": [
    "def find_unique_words(strings):\n",
    "        combined_string = ' '.join(strings)\n",
    "        words = combined_string.split()\n",
    "        unique_words = set(words)\n",
    "        return unique_words\n",
    "\n",
    "unique_words = find_unique_words(data[\"Text\"])\n",
    "print(len(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the vectorizer model\n",
    "vectorizer = gensim.models.KeyedVectors.load_word2vec_format(r'..\\Vectorizer\\FastText-300d-1M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the keras tokenizer on the entire dataset\n",
    "tokenizer = keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(data['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# + 1 to account for padding token.\n",
    "num_tokens = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Initialize a matrix of zeroes of size: vocabulary x embedding dimension.\n",
    "embedding_dim = 300\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "  if vectorizer.has_index_for(word):\n",
    "    embedding_matrix[i] = vectorizer[word].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0129 -0.0311  0.0133  0.0051 -0.0395 -0.0044 -0.0218 -0.0483  0.021\n",
      "  0.0186 -0.0313  0.0012  0.0194 -0.0124  0.0116 -0.0149  0.0489  0.0029\n",
      "  0.0437 -0.0069 -0.0129  0.0165 -0.0162  0.0322  0.0181 -0.01    0.0173\n",
      " -0.0312  0.0552 -0.0006 -0.0004 -0.0177  0.0048 -0.0616  0.0065 -0.0015\n",
      "  0.0203 -0.0142 -0.0047  0.0054  0.0096  0.0071 -0.0081 -0.0085 -0.0088\n",
      "  0.0129  0.0017 -0.0259  0.0174  0.0354]\n"
     ]
    }
   ],
   "source": [
    "# Quick check\n",
    "print(embedding_matrix[tokenizer.word_index['great']][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'..\\Dataset3\\embeddingMatrixDS3.pkl', 'wb') as f:\n",
    "    pickle.dump(embedding_matrix, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Text'], np.array(data['Category']), test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'food and drinks': 19189, 'real estate': 19149, 'family and relationships': 19073, 'news and politics': 19041, 'sports': 19031, 'style and fashion': 19003, 'arts and culture': 19002, 'hobbies and interests': 18981, 'business and finance': 18977, 'healthy living': 18954})\n",
      "Counter({'news and politics': 4888, 'style and fashion': 4799, 'hobbies and interests': 4795, 'sports': 4761, 'arts and culture': 4755, 'family and relationships': 4752, 'business and finance': 4737, 'healthy living': 4717, 'real estate': 4710, 'food and drinks': 4686})\n",
      "Counter({'healthy living': 4329, 'business and finance': 4286, 'arts and culture': 4243, 'hobbies and interests': 4224, 'sports': 4208, 'style and fashion': 4198, 'family and relationships': 4175, 'real estate': 4141, 'food and drinks': 4125, 'news and politics': 4071})\n"
     ]
    }
   ],
   "source": [
    "print(collections.Counter(y_train))\n",
    "print(collections.Counter(y_val))\n",
    "print(collections.Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 67, 67, 143, 52, 2668, 2651, 413, 1147, 195, 6, 331, 330, 542, 6992, 20506, 1555, 38, 104, 4491, 20, 5362, 360, 1149, 6089, 8, 218, 10024, 298, 1685, 1472, 2367, 1839, 3124, 858, 10727, 203, 106918, 721, 517, 2071, 50141, 183, 491, 6992, 3495, 711, 858, 203, 3124, 442, 79, 47, 1473, 1839, 21, 3124, 9, 850, 149, 6992, 20506, 2755, 2651, 1, 357, 7946, 2, 1, 6992, 20506, 885, 850, 151, 9, 50536, 297, 1547, 17994, 381, 1190, 6851, 228, 6992, 20506, 3853, 16, 90, 309, 2071, 101, 907, 7, 896, 54, 1147, 195, 330, 542, 6992, 20506, 1]\n"
     ]
    }
   ],
   "source": [
    "print(X_val_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new', 'delhi', 'delhi', 'chief', 'minister']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.index_word[x] for x in X_val_seq[0][:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new delhi delhi chief minister arvind kejriwal monday urge centre take step ensure security kashmiri pandits wake last week killing government servant community rahul bhat get job clerk special employment package migrant gun terrorist inside tehsil office chadoora town central kashmir budgam distric'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([X_val_seq[0]])[0][:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NEWS_LEN = 500\n",
    "X_train_padded = keras.preprocessing.sequence.pad_sequences(X_train_seq, maxlen=MAX_NEWS_LEN, padding='post')\n",
    "X_val_padded = keras.preprocessing.sequence.pad_sequences(X_val_seq, maxlen=MAX_NEWS_LEN, padding='post')\n",
    "X_test_padded = keras.preprocessing.sequence.pad_sequences(X_test_seq, maxlen=MAX_NEWS_LEN, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'..\\Dataset3\\Dataset3Splits\\X_train.pkl', 'wb') as f:\n",
    "    pickle.dump(X_train_padded, f)\n",
    "\n",
    "with open(r'..\\Dataset3\\Dataset3Splits\\X_val.pkl', 'wb') as f:\n",
    "    pickle.dump(X_val_padded, f)\n",
    "\n",
    "with open(r'..\\Dataset3\\Dataset3Splits\\X_test.pkl', 'wb') as f:\n",
    "    pickle.dump(X_test_padded, f)\n",
    "\n",
    "with open(r'..\\Dataset3\\Dataset3Splits\\y_train.pkl', 'wb') as f:\n",
    "    pickle.dump(y_train, f)\n",
    "\n",
    "with open(r'..\\Dataset3\\Dataset3Splits\\y_val.pkl', 'wb') as f:\n",
    "    pickle.dump(y_val, f)\n",
    "\n",
    "with open(r'..\\Dataset3\\Dataset3Splits\\y_test.pkl', 'wb') as f:\n",
    "    pickle.dump(y_test, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
